{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v7xZHddZym_c",
    "outputId": "75ffa4ba-9671-4609-e293-f485280b82f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.9.0.80-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\asus\\.conda\\envs\\tf\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Downloading opencv_python-4.9.0.80-cp37-abi3-win_amd64.whl (38.6 MB)\n",
      "   ---------------------------------------- 0.0/38.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/38.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/38.6 MB 812.7 kB/s eta 0:00:48\n",
      "   ---------------------------------------- 0.2/38.6 MB 1.6 MB/s eta 0:00:25\n",
      "   ---------------------------------------- 0.5/38.6 MB 2.9 MB/s eta 0:00:13\n",
      "    --------------------------------------- 0.8/38.6 MB 3.7 MB/s eta 0:00:11\n",
      "   - -------------------------------------- 1.1/38.6 MB 4.2 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 1.4/38.6 MB 4.5 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 1.6/38.6 MB 4.8 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 2.0/38.6 MB 5.0 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 2.3/38.6 MB 5.3 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 2.6/38.6 MB 5.3 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 2.9/38.6 MB 5.5 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 3.1/38.6 MB 5.5 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 3.4/38.6 MB 5.6 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 3.7/38.6 MB 5.7 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 4.1/38.6 MB 5.6 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 4.4/38.6 MB 5.7 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 4.6/38.6 MB 5.8 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 5.0/38.6 MB 5.9 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 5.2/38.6 MB 5.9 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 5.6/38.6 MB 5.8 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 5.8/38.6 MB 5.9 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 6.1/38.6 MB 5.9 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 6.5/38.6 MB 6.0 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 6.7/38.6 MB 6.0 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 7.0/38.6 MB 6.0 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 7.3/38.6 MB 6.0 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 7.6/38.6 MB 6.0 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 7.9/38.6 MB 6.0 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 8.2/38.6 MB 6.0 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 8.5/38.6 MB 6.1 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 8.8/38.6 MB 6.1 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 9.1/38.6 MB 6.1 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 9.4/38.6 MB 6.1 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 9.7/38.6 MB 6.1 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 10.0/38.6 MB 6.1 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 10.3/38.6 MB 6.4 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 10.6/38.6 MB 6.4 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 10.9/38.6 MB 6.4 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 11.2/38.6 MB 6.4 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 11.5/38.6 MB 6.4 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 11.8/38.6 MB 6.4 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 12.1/38.6 MB 6.4 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 12.4/38.6 MB 6.4 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 12.7/38.6 MB 6.4 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 13.0/38.6 MB 6.4 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 13.3/38.6 MB 6.4 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 13.6/38.6 MB 6.4 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 13.9/38.6 MB 6.4 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 14.2/38.6 MB 6.4 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 14.5/38.6 MB 6.4 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 14.8/38.6 MB 6.4 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 15.1/38.6 MB 6.4 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 15.4/38.6 MB 6.4 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 15.7/38.6 MB 6.4 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 16.0/38.6 MB 6.4 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 16.3/38.6 MB 6.4 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 16.6/38.6 MB 6.4 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 16.9/38.6 MB 6.4 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 17.2/38.6 MB 6.4 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 17.5/38.6 MB 6.4 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 17.8/38.6 MB 6.4 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 18.1/38.6 MB 6.4 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 18.4/38.6 MB 6.4 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 18.6/38.6 MB 6.4 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 19.0/38.6 MB 6.4 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 19.3/38.6 MB 6.4 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 19.6/38.6 MB 6.4 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 19.9/38.6 MB 6.4 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 20.2/38.6 MB 6.4 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 20.5/38.6 MB 6.4 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 20.8/38.6 MB 6.4 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 21.1/38.6 MB 6.4 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 21.4/38.6 MB 6.4 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 21.7/38.6 MB 6.4 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 22.0/38.6 MB 6.4 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 22.2/38.6 MB 6.4 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 22.5/38.6 MB 6.4 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 22.8/38.6 MB 6.4 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 23.1/38.6 MB 6.4 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 23.5/38.6 MB 6.4 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 23.8/38.6 MB 6.4 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 24.0/38.6 MB 6.4 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 24.4/38.6 MB 6.4 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 24.7/38.6 MB 6.4 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 24.9/38.6 MB 6.4 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 25.2/38.6 MB 6.4 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 25.6/38.6 MB 6.4 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 25.9/38.6 MB 6.4 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 26.2/38.6 MB 6.4 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 26.4/38.6 MB 6.4 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 26.8/38.6 MB 6.4 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 27.0/38.6 MB 6.4 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 27.4/38.6 MB 6.4 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 27.7/38.6 MB 6.4 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 27.9/38.6 MB 6.4 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 28.2/38.6 MB 6.4 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 28.5/38.6 MB 6.4 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 28.8/38.6 MB 6.4 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 29.1/38.6 MB 6.4 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 29.5/38.6 MB 6.4 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 29.7/38.6 MB 6.4 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 30.0/38.6 MB 6.4 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 30.3/38.6 MB 6.4 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 30.6/38.6 MB 6.4 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 30.9/38.6 MB 6.4 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 31.2/38.6 MB 6.4 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 31.5/38.6 MB 6.4 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 31.8/38.6 MB 6.4 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 32.1/38.6 MB 6.4 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 32.4/38.6 MB 6.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 32.7/38.6 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 33.0/38.6 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 33.3/38.6 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 33.6/38.6 MB 6.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 33.9/38.6 MB 6.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.2/38.6 MB 6.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.5/38.6 MB 6.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 34.8/38.6 MB 6.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 35.1/38.6 MB 6.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 35.4/38.6 MB 6.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 35.7/38.6 MB 6.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 36.0/38.6 MB 6.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 36.3/38.6 MB 6.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 36.6/38.6 MB 6.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 36.9/38.6 MB 6.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 37.2/38.6 MB 6.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 37.5/38.6 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  37.8/38.6 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.0/38.6 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.4/38.6 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.6/38.6 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.6/38.6 MB 6.1 MB/s eta 0:00:00\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.9.0.80\n"
     ]
    }
   ],
   "source": [
    "# !pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: FuzzyTM in d:\\softwares\\anaconda\\lib\\site-packages (2.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (from FuzzyTM) (1.23.5)\n",
      "Requirement already satisfied: pandas in d:\\softwares\\anaconda\\lib\\site-packages (from FuzzyTM) (2.1.4)\n",
      "Requirement already satisfied: scipy in d:\\softwares\\anaconda\\lib\\site-packages (from FuzzyTM) (1.11.4)\n",
      "Requirement already satisfied: pyfume in d:\\softwares\\anaconda\\lib\\site-packages (from FuzzyTM) (0.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\softwares\\anaconda\\lib\\site-packages (from pandas->FuzzyTM) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\softwares\\anaconda\\lib\\site-packages (from pandas->FuzzyTM) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in d:\\softwares\\anaconda\\lib\\site-packages (from pandas->FuzzyTM) (2023.3)\n",
      "Requirement already satisfied: simpful in d:\\softwares\\anaconda\\lib\\site-packages (from pyfume->FuzzyTM) (2.12.0)\n",
      "Requirement already satisfied: fst-pso in d:\\softwares\\anaconda\\lib\\site-packages (from pyfume->FuzzyTM) (1.8.1)\n",
      "Requirement already satisfied: six>=1.5 in d:\\softwares\\anaconda\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->FuzzyTM) (1.16.0)\n",
      "Requirement already satisfied: miniful in d:\\softwares\\anaconda\\lib\\site-packages (from fst-pso->pyfume->FuzzyTM) (0.0.6)\n"
     ]
    }
   ],
   "source": [
    "# !pip install FuzzyTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (1.23.5)\n"
     ]
    }
   ],
   "source": [
    "# !pip install numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "z29BxipFnogl"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('fer2013.csv')\n",
    "X_test = []\n",
    "y_test = []\n",
    "X_train = []\n",
    "y_train = []\n",
    "for index, row in df.iterrows():\n",
    "  k = row['pixels'].split(\" \")\n",
    "  if row['Usage'] == \"Training\":\n",
    "    X_train.append(np.array(k))\n",
    "    y_train.append(row['emotion'])\n",
    "  elif row['Usage'] == \"PublicTest\":\n",
    "    X_test.append(np.array(k))\n",
    "    y_test.append(row['emotion'])\n",
    "X_train = np.array(X_train, dtype = 'uint8')\n",
    "y_train = np.array(y_train, dtype = 'uint8')\n",
    "X_test = np.array(X_test, dtype = 'uint8')\n",
    "y_test = np.array(y_test, dtype = 'uint8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                             pixels     Usage\n",
       "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
       "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
       "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
       "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
       "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 70,  80,  82, ..., 106, 109,  82], dtype=uint8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "rEZslMSHsJJJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HELLO\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train,num_classes = 7)\n",
    "y_test = to_categorical(y_test,num_classes = 7)\n",
    "print(\"HELLO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 70,  80,  82, ..., 106, 109,  82],\n",
       "       [151, 150, 147, ..., 193, 183, 184],\n",
       "       [231, 212, 156, ...,  88, 110, 152],\n",
       "       ...,\n",
       "       [ 74,  81,  87, ..., 188, 187, 187],\n",
       "       [222, 227, 203, ..., 136, 136, 134],\n",
       "       [195, 199, 205, ...,   6,  15,  38]], dtype=uint8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "SJ8IqAbXsvHi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HELLO\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 48, 48, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 48, 48, 1)\n",
    "print(\"HELLO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "dQmmCB2_xAwc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HELLO\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range = 10,\n",
    "    horizontal_flip = True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    fill_mode = 'nearest')\n",
    "testgen = ImageDataGenerator(rescale=1./255)\n",
    "datagen.fit(X_train)\n",
    "batch_size = 64\n",
    "print(\"HELLO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "QTKbpmecxDnX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HELLO\n"
     ]
    }
   ],
   "source": [
    "train_flow = datagen.flow(X_train, y_train, batch_size=batch_size)\n",
    "test_flow = testgen.flow(X_test, y_test, batch_size=batch_size)\n",
    "print(\"HELLO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "ZhmraR1Xxb6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HELLO\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers import concatenate\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.regularizers import l1, l2\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(\"HELLO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "EI1NCyRzxhc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HELLO\n"
     ]
    }
   ],
   "source": [
    "def FER_Model(input_shape=(48,48,1)):\n",
    "    # first input model\n",
    "    visible = Input(shape=input_shape, name='input')\n",
    "    num_classes = 7\n",
    "    #the 1-st block\n",
    "    conv1_1 = Conv2D(64, kernel_size=3, activation='relu', padding='same', name = 'conv1_1')(visible)\n",
    "    conv1_1 = BatchNormalization()(conv1_1)\n",
    "    conv1_2 = Conv2D(64, kernel_size=3, activation='relu', padding='same', name = 'conv1_2')(conv1_1)\n",
    "    conv1_2 = BatchNormalization()(conv1_2)\n",
    "    pool1_1 = MaxPooling2D(pool_size=(2,2), name = 'pool1_1')(conv1_2)\n",
    "    drop1_1 = Dropout(0.3, name = 'drop1_1')(pool1_1)#the 2-nd block\n",
    "    conv2_1 = Conv2D(128, kernel_size=3, activation='relu', padding='same', name = 'conv2_1')(drop1_1)\n",
    "    conv2_1 = BatchNormalization()(conv2_1)\n",
    "    conv2_2 = Conv2D(128, kernel_size=3, activation='relu', padding='same', name = 'conv2_2')(conv2_1)\n",
    "    conv2_2 = BatchNormalization()(conv2_2)\n",
    "    conv2_3 = Conv2D(128, kernel_size=3, activation='relu', padding='same', name = 'conv2_3')(conv2_2)\n",
    "    conv2_2 = BatchNormalization()(conv2_3)\n",
    "    pool2_1 = MaxPooling2D(pool_size=(2,2), name = 'pool2_1')(conv2_3)\n",
    "    drop2_1 = Dropout(0.3, name = 'drop2_1')(pool2_1)#the 3-rd block\n",
    "    conv3_1 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_1')(drop2_1)\n",
    "    conv3_1 = BatchNormalization()(conv3_1)\n",
    "    conv3_2 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_2')(conv3_1)\n",
    "    conv3_2 = BatchNormalization()(conv3_2)\n",
    "    conv3_3 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_3')(conv3_2)\n",
    "    conv3_3 = BatchNormalization()(conv3_3)\n",
    "    conv3_4 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_4')(conv3_3)\n",
    "    conv3_4 = BatchNormalization()(conv3_4)\n",
    "    pool3_1 = MaxPooling2D(pool_size=(2,2), name = 'pool3_1')(conv3_4)\n",
    "    drop3_1 = Dropout(0.3, name = 'drop3_1')(pool3_1)#the 4-th block\n",
    "    conv4_1 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_1')(drop3_1)\n",
    "    conv4_1 = BatchNormalization()(conv4_1)\n",
    "    conv4_2 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_2')(conv4_1)\n",
    "    conv4_2 = BatchNormalization()(conv4_2)\n",
    "    conv4_3 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_3')(conv4_2)\n",
    "    conv4_3 = BatchNormalization()(conv4_3)\n",
    "    conv4_4 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_4')(conv4_3)\n",
    "    conv4_4 = BatchNormalization()(conv4_4)\n",
    "    pool4_1 = MaxPooling2D(pool_size=(2,2), name = 'pool4_1')(conv4_4)\n",
    "    drop4_1 = Dropout(0.3, name = 'drop4_1')(pool4_1)\n",
    "\n",
    "    #the 5-th block\n",
    "    conv5_1 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_1')(drop4_1)\n",
    "    conv5_1 = BatchNormalization()(conv5_1)\n",
    "    conv5_2 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_2')(conv5_1)\n",
    "    conv5_2 = BatchNormalization()(conv5_2)\n",
    "    conv5_3 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_3')(conv5_2)\n",
    "    conv5_3 = BatchNormalization()(conv5_3)\n",
    "    conv5_4 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_4')(conv5_3)\n",
    "    conv5_3 = BatchNormalization()(conv5_3)\n",
    "    pool5_1 = MaxPooling2D(pool_size=(2,2), name = 'pool5_1')(conv5_4)\n",
    "    drop5_1 = Dropout(0.3, name = 'drop5_1')(pool5_1)#Flatten and output\n",
    "    flatten = Flatten(name = 'flatten')(drop5_1)\n",
    "    ouput = Dense(num_classes, activation='softmax', name = 'output')(flatten)# create model\n",
    "    model = Model(inputs =visible, outputs = ouput)\n",
    "    # summary layers\n",
    "    print(model.summary())\n",
    "\n",
    "    return model\n",
    "print(\"HELLO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ykR2LrCJxo4Y",
    "outputId": "88bf21e2-39bb-45be-cf46-67461a13ae4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 48, 48, 1)]       0         \n",
      "                                                                 \n",
      " conv1_1 (Conv2D)            (None, 48, 48, 64)        640       \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 48, 48, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv1_2 (Conv2D)            (None, 48, 48, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 48, 48, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " pool1_1 (MaxPooling2D)      (None, 24, 24, 64)        0         \n",
      "                                                                 \n",
      " drop1_1 (Dropout)           (None, 24, 24, 64)        0         \n",
      "                                                                 \n",
      " conv2_1 (Conv2D)            (None, 24, 24, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 24, 24, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2_2 (Conv2D)            (None, 24, 24, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  (None, 24, 24, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2_3 (Conv2D)            (None, 24, 24, 128)       147584    \n",
      "                                                                 \n",
      " pool2_1 (MaxPooling2D)      (None, 12, 12, 128)       0         \n",
      "                                                                 \n",
      " drop2_1 (Dropout)           (None, 12, 12, 128)       0         \n",
      "                                                                 \n",
      " conv3_1 (Conv2D)            (None, 12, 12, 256)       295168    \n",
      "                                                                 \n",
      " batch_normalization_22 (Bat  (None, 12, 12, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv3_2 (Conv2D)            (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " batch_normalization_23 (Bat  (None, 12, 12, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv3_3 (Conv2D)            (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " batch_normalization_24 (Bat  (None, 12, 12, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv3_4 (Conv2D)            (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " batch_normalization_25 (Bat  (None, 12, 12, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " pool3_1 (MaxPooling2D)      (None, 6, 6, 256)         0         \n",
      "                                                                 \n",
      " drop3_1 (Dropout)           (None, 6, 6, 256)         0         \n",
      "                                                                 \n",
      " conv4_1 (Conv2D)            (None, 6, 6, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_26 (Bat  (None, 6, 6, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv4_2 (Conv2D)            (None, 6, 6, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_27 (Bat  (None, 6, 6, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv4_3 (Conv2D)            (None, 6, 6, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_28 (Bat  (None, 6, 6, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv4_4 (Conv2D)            (None, 6, 6, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_29 (Bat  (None, 6, 6, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " pool4_1 (MaxPooling2D)      (None, 3, 3, 256)         0         \n",
      "                                                                 \n",
      " drop4_1 (Dropout)           (None, 3, 3, 256)         0         \n",
      "                                                                 \n",
      " conv5_1 (Conv2D)            (None, 3, 3, 512)         1180160   \n",
      "                                                                 \n",
      " batch_normalization_30 (Bat  (None, 3, 3, 512)        2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv5_2 (Conv2D)            (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_31 (Bat  (None, 3, 3, 512)        2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv5_3 (Conv2D)            (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_32 (Bat  (None, 3, 3, 512)        2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv5_4 (Conv2D)            (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " pool5_1 (MaxPooling2D)      (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " drop5_1 (Dropout)           (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 7)                 3591      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,111,367\n",
      "Trainable params: 13,103,431\n",
      "Non-trainable params: 7,936\n",
      "_________________________________________________________________\n",
      "None\n",
      "HELLO\n"
     ]
    }
   ],
   "source": [
    "model = FER_Model()\n",
    "opt = Adam(learning_rate=0.0001, decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "print(\"HELLO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sirtce6bxvii",
    "outputId": "7369e030-f15c-4002-f4ac-e8119f89f0cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_3168\\512580939.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(train_flow,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448/448 [==============================] - 83s 184ms/step - loss: 1.8209 - accuracy: 0.2408 - val_loss: 1.9224 - val_accuracy: 0.2215\n",
      "Epoch 2/3\n",
      "448/448 [==============================] - 83s 185ms/step - loss: 1.7733 - accuracy: 0.2641 - val_loss: 1.8932 - val_accuracy: 0.2569\n",
      "Epoch 3/3\n",
      "448/448 [==============================] - 76s 169ms/step - loss: 1.7436 - accuracy: 0.2840 - val_loss: 2.0244 - val_accuracy: 0.2683\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "history = model.fit_generator(train_flow,\n",
    "                              steps_per_epoch=len(X_train) / batch_size,\n",
    "                              epochs=num_epochs,\n",
    "                              verbose=1,\n",
    "                              validation_data=test_flow,\n",
    "                              validation_steps = len(X_test)/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "model = model_from_json(open(\"model.json\", \"r\").read())\n",
    "model.load_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "face_haar_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "True\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function destroyAllWindows>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model, model_from_json\n",
    "from tensorflow.keras.preprocessing.image import load_img,img_to_array\n",
    "from tensorflow.keras.preprocessing import image\n",
    "model = model_from_json(open(\"model.json\", \"r\").read())\n",
    "model.load_weights('model.h5')\n",
    "# model = load_model('static\\Fer2013.h5')\n",
    "face_haar_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "if face_haar_cascade.empty():\n",
    "    print(\"Error loading cascade classifier XML file.\")\n",
    "\n",
    "cap=cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    res,frame=cap.read()\n",
    "    print(res)  # Print the value of res\n",
    "\n",
    "    height, width , channel = frame.shape\n",
    "    sub_img = frame[0:int(height/6),0:int(width)]\n",
    "\n",
    "    black_rect = np.ones(sub_img.shape, dtype=np.uint8)*0\n",
    "    res = cv2.addWeighted(sub_img, 0.77, black_rect,0.23, 0)\n",
    "    FONT = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    FONT_SCALE = 0.8\n",
    "    FONT_THICKNESS = 2\n",
    "    lable_color = (10, 10, 255)\n",
    "    lable = \"Detecting Emotions now...\"\n",
    "    lable_dimension = cv2.getTextSize(lable,FONT ,FONT_SCALE,FONT_THICKNESS)[0]\n",
    "    textX = int((res.shape[1] - lable_dimension[0]) / 2)\n",
    "    textY = int((res.shape[0] + lable_dimension[1]) / 2)\n",
    "    cv2.putText(res, lable, (textX,textY), FONT, FONT_SCALE, (0,0,0), FONT_THICKNESS)\n",
    "    gray_image= cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_haar_cascade.detectMultiScale(gray_image)\n",
    "    if frame is None:\n",
    "        print(\"Frame is None. Check your camera connection or configuration.\")\n",
    "        break  # Break out of the loop if frame is None\n",
    "\n",
    "    try:\n",
    "        for (x,y, w, h) in faces:\n",
    "            cv2.rectangle(frame, pt1 = (x,y),pt2 = (x+w, y+h), color = (255,0,0),thickness =  2)\n",
    "            roi_gray = gray_image[y-5:y+h+5,x-5:x+w+5]\n",
    "            roi_gray=cv2.resize(roi_gray,(48,48))\n",
    "            image_pixels = img_to_array(roi_gray)\n",
    "            image_pixels = np.expand_dims(image_pixels, axis = 0)\n",
    "            image_pixels /= 255\n",
    "            predictions = model.predict(image_pixels)\n",
    "            max_index = np.argmax(predictions[0])\n",
    "            emotion_detection = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
    "            emotion_prediction = emotion_detection[max_index]\n",
    "            cv2.putText(res, \"Sentiment: {}\".format(emotion_prediction), (0,textY+22+5), FONT,0.7, lable_color,2)\n",
    "            lable_violation = 'Confidence: {}'.format(str(np.round(np.max(predictions[0])*100,1))+ \"%\")\n",
    "            violation_text_dimension = cv2.getTextSize(lable_violation,FONT,FONT_SCALE,FONT_THICKNESS )[0]\n",
    "            violation_x_axis = int(res.shape[1]- violation_text_dimension[0])\n",
    "            cv2.putText(res, lable_violation, (violation_x_axis,textY+22+5), FONT,0.7, lable_color,2)\n",
    "    except :\n",
    "        pass\n",
    "    frame[0:int(height/6),0:int(width)] =res\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function destroyAllWindows>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.11 (tf)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
