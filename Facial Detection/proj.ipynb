{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v7xZHddZym_c",
    "outputId": "75ffa4ba-9671-4609-e293-f485280b82f3"
   },
   "outputs": [],
   "source": [
    "# !pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install FuzzyTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "z29BxipFnogl"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('fer2013.csv')\n",
    "X_test = []\n",
    "y_test = []\n",
    "X_train = []\n",
    "y_train = []\n",
    "for index, row in df.iterrows():\n",
    "  k = row['pixels'].split(\" \")\n",
    "  if row['Usage'] == \"Training\":\n",
    "    X_train.append(np.array(k))\n",
    "    y_train.append(row['emotion'])\n",
    "  elif row['Usage'] == \"PublicTest\":\n",
    "    X_test.append(np.array(k))\n",
    "    y_test.append(row['emotion'])\n",
    "X_train = np.array(X_train, dtype = 'uint8')\n",
    "y_train = np.array(y_train, dtype = 'uint8')\n",
    "X_test = np.array(X_test, dtype = 'uint8')\n",
    "y_test = np.array(y_test, dtype = 'uint8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                             pixels     Usage\n",
       "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
       "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
       "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
       "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
       "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 70,  80,  82, ..., 106, 109,  82], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "rEZslMSHsJJJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HELLO\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train,num_classes = 7)\n",
    "y_test = to_categorical(y_test,num_classes = 7)\n",
    "print(\"HELLO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 70,  80,  82, ..., 106, 109,  82],\n",
       "       [151, 150, 147, ..., 193, 183, 184],\n",
       "       [231, 212, 156, ...,  88, 110, 152],\n",
       "       ...,\n",
       "       [ 74,  81,  87, ..., 188, 187, 187],\n",
       "       [222, 227, 203, ..., 136, 136, 134],\n",
       "       [195, 199, 205, ...,   6,  15,  38]], dtype=uint8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "SJ8IqAbXsvHi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HELLO\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 48, 48, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 48, 48, 1)\n",
    "print(\"HELLO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "dQmmCB2_xAwc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HELLO\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range = 10,\n",
    "    horizontal_flip = True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    fill_mode = 'nearest')\n",
    "testgen = ImageDataGenerator(rescale=1./255)\n",
    "datagen.fit(X_train)\n",
    "batch_size = 64\n",
    "print(\"HELLO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "QTKbpmecxDnX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HELLO\n"
     ]
    }
   ],
   "source": [
    "train_flow = datagen.flow(X_train, y_train, batch_size=batch_size)\n",
    "test_flow = testgen.flow(X_test, y_test, batch_size=batch_size)\n",
    "print(\"HELLO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ZhmraR1Xxb6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HELLO\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers import concatenate\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.regularizers import l1, l2\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(\"HELLO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "EI1NCyRzxhc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HELLO\n"
     ]
    }
   ],
   "source": [
    "def FER_Model(input_shape=(48,48,1)):\n",
    "    # first input model\n",
    "    visible = Input(shape=input_shape, name='input')\n",
    "    num_classes = 7\n",
    "    #the 1-st block\n",
    "    conv1_1 = Conv2D(64, kernel_size=3, activation='relu', padding='same', name = 'conv1_1')(visible)\n",
    "    conv1_1 = BatchNormalization()(conv1_1)\n",
    "    conv1_2 = Conv2D(64, kernel_size=3, activation='relu', padding='same', name = 'conv1_2')(conv1_1)\n",
    "    conv1_2 = BatchNormalization()(conv1_2)\n",
    "    pool1_1 = MaxPooling2D(pool_size=(2,2), name = 'pool1_1')(conv1_2)\n",
    "    drop1_1 = Dropout(0.3, name = 'drop1_1')(pool1_1)#the 2-nd block\n",
    "    conv2_1 = Conv2D(128, kernel_size=3, activation='relu', padding='same', name = 'conv2_1')(drop1_1)\n",
    "    conv2_1 = BatchNormalization()(conv2_1)\n",
    "    conv2_2 = Conv2D(128, kernel_size=3, activation='relu', padding='same', name = 'conv2_2')(conv2_1)\n",
    "    conv2_2 = BatchNormalization()(conv2_2)\n",
    "    conv2_3 = Conv2D(128, kernel_size=3, activation='relu', padding='same', name = 'conv2_3')(conv2_2)\n",
    "    conv2_2 = BatchNormalization()(conv2_3)\n",
    "    pool2_1 = MaxPooling2D(pool_size=(2,2), name = 'pool2_1')(conv2_3)\n",
    "    drop2_1 = Dropout(0.3, name = 'drop2_1')(pool2_1)#the 3-rd block\n",
    "    conv3_1 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_1')(drop2_1)\n",
    "    conv3_1 = BatchNormalization()(conv3_1)\n",
    "    conv3_2 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_2')(conv3_1)\n",
    "    conv3_2 = BatchNormalization()(conv3_2)\n",
    "    conv3_3 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_3')(conv3_2)\n",
    "    conv3_3 = BatchNormalization()(conv3_3)\n",
    "    conv3_4 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_4')(conv3_3)\n",
    "    conv3_4 = BatchNormalization()(conv3_4)\n",
    "    pool3_1 = MaxPooling2D(pool_size=(2,2), name = 'pool3_1')(conv3_4)\n",
    "    drop3_1 = Dropout(0.3, name = 'drop3_1')(pool3_1)#the 4-th block\n",
    "    conv4_1 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_1')(drop3_1)\n",
    "    conv4_1 = BatchNormalization()(conv4_1)\n",
    "    conv4_2 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_2')(conv4_1)\n",
    "    conv4_2 = BatchNormalization()(conv4_2)\n",
    "    conv4_3 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_3')(conv4_2)\n",
    "    conv4_3 = BatchNormalization()(conv4_3)\n",
    "    conv4_4 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_4')(conv4_3)\n",
    "    conv4_4 = BatchNormalization()(conv4_4)\n",
    "    pool4_1 = MaxPooling2D(pool_size=(2,2), name = 'pool4_1')(conv4_4)\n",
    "    drop4_1 = Dropout(0.3, name = 'drop4_1')(pool4_1)\n",
    "\n",
    "    #the 5-th block\n",
    "    conv5_1 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_1')(drop4_1)\n",
    "    conv5_1 = BatchNormalization()(conv5_1)\n",
    "    conv5_2 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_2')(conv5_1)\n",
    "    conv5_2 = BatchNormalization()(conv5_2)\n",
    "    conv5_3 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_3')(conv5_2)\n",
    "    conv5_3 = BatchNormalization()(conv5_3)\n",
    "    conv5_4 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_4')(conv5_3)\n",
    "    conv5_3 = BatchNormalization()(conv5_3)\n",
    "    pool5_1 = MaxPooling2D(pool_size=(2,2), name = 'pool5_1')(conv5_4)\n",
    "    drop5_1 = Dropout(0.3, name = 'drop5_1')(pool5_1)#Flatten and output\n",
    "    flatten = Flatten(name = 'flatten')(drop5_1)\n",
    "    ouput = Dense(num_classes, activation='softmax', name = 'output')(flatten)# create model\n",
    "    model = Model(inputs =visible, outputs = ouput)\n",
    "    # summary layers\n",
    "    print(model.summary())\n",
    "\n",
    "    return model\n",
    "print(\"HELLO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ykR2LrCJxo4Y",
    "outputId": "88bf21e2-39bb-45be-cf46-67461a13ae4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 48, 48, 1)]       0         \n",
      "                                                                 \n",
      " conv1_1 (Conv2D)            (None, 48, 48, 64)        640       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 48, 48, 64)       256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv1_2 (Conv2D)            (None, 48, 48, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 48, 48, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " pool1_1 (MaxPooling2D)      (None, 24, 24, 64)        0         \n",
      "                                                                 \n",
      " drop1_1 (Dropout)           (None, 24, 24, 64)        0         \n",
      "                                                                 \n",
      " conv2_1 (Conv2D)            (None, 24, 24, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 24, 24, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2_2 (Conv2D)            (None, 24, 24, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 24, 24, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2_3 (Conv2D)            (None, 24, 24, 128)       147584    \n",
      "                                                                 \n",
      " pool2_1 (MaxPooling2D)      (None, 12, 12, 128)       0         \n",
      "                                                                 \n",
      " drop2_1 (Dropout)           (None, 12, 12, 128)       0         \n",
      "                                                                 \n",
      " conv3_1 (Conv2D)            (None, 12, 12, 256)       295168    \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 12, 12, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv3_2 (Conv2D)            (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 12, 12, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv3_3 (Conv2D)            (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 12, 12, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv3_4 (Conv2D)            (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 12, 12, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " pool3_1 (MaxPooling2D)      (None, 6, 6, 256)         0         \n",
      "                                                                 \n",
      " drop3_1 (Dropout)           (None, 6, 6, 256)         0         \n",
      "                                                                 \n",
      " conv4_1 (Conv2D)            (None, 6, 6, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 6, 6, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv4_2 (Conv2D)            (None, 6, 6, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 6, 6, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv4_3 (Conv2D)            (None, 6, 6, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 6, 6, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv4_4 (Conv2D)            (None, 6, 6, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 6, 6, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " pool4_1 (MaxPooling2D)      (None, 3, 3, 256)         0         \n",
      "                                                                 \n",
      " drop4_1 (Dropout)           (None, 3, 3, 256)         0         \n",
      "                                                                 \n",
      " conv5_1 (Conv2D)            (None, 3, 3, 512)         1180160   \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 3, 3, 512)        2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv5_2 (Conv2D)            (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 3, 3, 512)        2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv5_3 (Conv2D)            (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 3, 3, 512)        2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv5_4 (Conv2D)            (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " pool5_1 (MaxPooling2D)      (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " drop5_1 (Dropout)           (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 7)                 3591      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,111,367\n",
      "Trainable params: 13,103,431\n",
      "Non-trainable params: 7,936\n",
      "_________________________________________________________________\n",
      "None\n",
      "HELLO\n"
     ]
    }
   ],
   "source": [
    "model = FER_Model()\n",
    "opt = Adam(learning_rate=0.0001, decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "print(\"HELLO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sirtce6bxvii",
    "outputId": "7369e030-f15c-4002-f4ac-e8119f89f0cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_31352\\1040513408.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(train_flow,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448/448 [==============================] - 65s 120ms/step - loss: 2.0232 - accuracy: 0.2141 - val_loss: 1.9001 - val_accuracy: 0.2508\n",
      "Epoch 2/100\n",
      "448/448 [==============================] - 54s 120ms/step - loss: 1.7916 - accuracy: 0.2487 - val_loss: 1.7643 - val_accuracy: 0.2728\n",
      "Epoch 3/100\n",
      "448/448 [==============================] - 54s 120ms/step - loss: 1.7626 - accuracy: 0.2710 - val_loss: 1.7413 - val_accuracy: 0.2839\n",
      "Epoch 4/100\n",
      "448/448 [==============================] - 54s 120ms/step - loss: 1.7179 - accuracy: 0.3056 - val_loss: 1.6914 - val_accuracy: 0.3369\n",
      "Epoch 5/100\n",
      "448/448 [==============================] - 54s 119ms/step - loss: 1.6563 - accuracy: 0.3436 - val_loss: 1.6095 - val_accuracy: 0.3901\n",
      "Epoch 6/100\n",
      "448/448 [==============================] - 54s 119ms/step - loss: 1.5817 - accuracy: 0.3795 - val_loss: 1.6407 - val_accuracy: 0.4099\n",
      "Epoch 7/100\n",
      "448/448 [==============================] - 53s 119ms/step - loss: 1.5119 - accuracy: 0.4104 - val_loss: 1.4660 - val_accuracy: 0.4450\n",
      "Epoch 8/100\n",
      "448/448 [==============================] - 54s 119ms/step - loss: 1.4335 - accuracy: 0.4470 - val_loss: 1.4363 - val_accuracy: 0.4753\n",
      "Epoch 9/100\n",
      "448/448 [==============================] - 54s 120ms/step - loss: 1.3611 - accuracy: 0.4756 - val_loss: 1.3362 - val_accuracy: 0.4932\n",
      "Epoch 10/100\n",
      "448/448 [==============================] - 54s 120ms/step - loss: 1.3009 - accuracy: 0.5007 - val_loss: 1.2752 - val_accuracy: 0.5063\n",
      "Epoch 11/100\n",
      "448/448 [==============================] - 57s 127ms/step - loss: 1.2634 - accuracy: 0.5206 - val_loss: 1.2147 - val_accuracy: 0.5339\n",
      "Epoch 12/100\n",
      "448/448 [==============================] - 82s 182ms/step - loss: 1.2248 - accuracy: 0.5345 - val_loss: 1.2401 - val_accuracy: 0.5414\n",
      "Epoch 13/100\n",
      "448/448 [==============================] - 82s 182ms/step - loss: 1.1961 - accuracy: 0.5499 - val_loss: 1.1739 - val_accuracy: 0.5559\n",
      "Epoch 14/100\n",
      "448/448 [==============================] - 81s 182ms/step - loss: 1.1626 - accuracy: 0.5609 - val_loss: 1.1836 - val_accuracy: 0.5598\n",
      "Epoch 15/100\n",
      "448/448 [==============================] - 81s 182ms/step - loss: 1.1344 - accuracy: 0.5730 - val_loss: 1.1228 - val_accuracy: 0.5737\n",
      "Epoch 16/100\n",
      "448/448 [==============================] - 81s 181ms/step - loss: 1.1112 - accuracy: 0.5777 - val_loss: 1.1401 - val_accuracy: 0.5812\n",
      "Epoch 17/100\n",
      "448/448 [==============================] - 81s 181ms/step - loss: 1.0865 - accuracy: 0.5873 - val_loss: 1.1256 - val_accuracy: 0.5871\n",
      "Epoch 18/100\n",
      "448/448 [==============================] - 81s 181ms/step - loss: 1.0653 - accuracy: 0.5998 - val_loss: 1.0795 - val_accuracy: 0.6055\n",
      "Epoch 19/100\n",
      "448/448 [==============================] - 81s 182ms/step - loss: 1.0462 - accuracy: 0.6095 - val_loss: 1.0562 - val_accuracy: 0.6119\n",
      "Epoch 20/100\n",
      "448/448 [==============================] - 82s 182ms/step - loss: 1.0259 - accuracy: 0.6166 - val_loss: 1.0444 - val_accuracy: 0.6147\n",
      "Epoch 21/100\n",
      "448/448 [==============================] - 81s 182ms/step - loss: 1.0171 - accuracy: 0.6190 - val_loss: 1.0639 - val_accuracy: 0.6099\n",
      "Epoch 22/100\n",
      "448/448 [==============================] - 81s 181ms/step - loss: 0.9999 - accuracy: 0.6286 - val_loss: 1.0536 - val_accuracy: 0.6007\n",
      "Epoch 23/100\n",
      "448/448 [==============================] - 81s 181ms/step - loss: 0.9829 - accuracy: 0.6288 - val_loss: 1.0466 - val_accuracy: 0.6149\n",
      "Epoch 24/100\n",
      "448/448 [==============================] - 81s 181ms/step - loss: 0.9604 - accuracy: 0.6398 - val_loss: 1.0246 - val_accuracy: 0.6174\n",
      "Epoch 25/100\n",
      "448/448 [==============================] - 81s 181ms/step - loss: 0.9459 - accuracy: 0.6453 - val_loss: 1.0141 - val_accuracy: 0.6272\n",
      "Epoch 26/100\n",
      "448/448 [==============================] - 81s 181ms/step - loss: 0.9407 - accuracy: 0.6456 - val_loss: 0.9886 - val_accuracy: 0.6330\n",
      "Epoch 27/100\n",
      "448/448 [==============================] - 81s 181ms/step - loss: 0.9168 - accuracy: 0.6552 - val_loss: 1.0282 - val_accuracy: 0.6247\n",
      "Epoch 28/100\n",
      "448/448 [==============================] - 81s 181ms/step - loss: 0.9164 - accuracy: 0.6587 - val_loss: 1.0119 - val_accuracy: 0.6308\n",
      "Epoch 29/100\n",
      "448/448 [==============================] - 81s 181ms/step - loss: 0.8982 - accuracy: 0.6675 - val_loss: 1.0563 - val_accuracy: 0.6236\n",
      "Epoch 30/100\n",
      "448/448 [==============================] - 81s 181ms/step - loss: 0.8857 - accuracy: 0.6697 - val_loss: 1.0089 - val_accuracy: 0.6350\n",
      "Epoch 31/100\n",
      "448/448 [==============================] - 81s 181ms/step - loss: 0.8661 - accuracy: 0.6753 - val_loss: 1.0148 - val_accuracy: 0.6230\n",
      "Epoch 32/100\n",
      "448/448 [==============================] - 81s 181ms/step - loss: 0.8631 - accuracy: 0.6782 - val_loss: 0.9888 - val_accuracy: 0.6459\n",
      "Epoch 33/100\n",
      "448/448 [==============================] - 81s 181ms/step - loss: 0.8449 - accuracy: 0.6835 - val_loss: 0.9916 - val_accuracy: 0.6395\n",
      "Epoch 34/100\n",
      "448/448 [==============================] - 81s 181ms/step - loss: 0.8400 - accuracy: 0.6849 - val_loss: 1.0210 - val_accuracy: 0.6495\n",
      "Epoch 35/100\n",
      "448/448 [==============================] - 81s 181ms/step - loss: 0.8236 - accuracy: 0.6935 - val_loss: 1.0099 - val_accuracy: 0.6395\n",
      "Epoch 36/100\n",
      "448/448 [==============================] - 81s 181ms/step - loss: 0.8135 - accuracy: 0.7004 - val_loss: 0.9717 - val_accuracy: 0.6473\n",
      "Epoch 37/100\n",
      "448/448 [==============================] - 81s 181ms/step - loss: 0.8050 - accuracy: 0.6999 - val_loss: 0.9909 - val_accuracy: 0.6565\n",
      "Epoch 38/100\n",
      "448/448 [==============================] - 81s 181ms/step - loss: 0.7910 - accuracy: 0.7017 - val_loss: 0.9834 - val_accuracy: 0.6556\n",
      "Epoch 39/100\n",
      "448/448 [==============================] - 81s 181ms/step - loss: 0.7807 - accuracy: 0.7080 - val_loss: 0.9684 - val_accuracy: 0.6670\n",
      "Epoch 40/100\n",
      "448/448 [==============================] - 81s 181ms/step - loss: 0.7748 - accuracy: 0.7122 - val_loss: 0.9972 - val_accuracy: 0.6358\n",
      "Epoch 41/100\n",
      "448/448 [==============================] - 82s 182ms/step - loss: 0.7549 - accuracy: 0.7192 - val_loss: 1.0060 - val_accuracy: 0.6565\n",
      "Epoch 42/100\n",
      "448/448 [==============================] - 81s 181ms/step - loss: 0.7479 - accuracy: 0.7226 - val_loss: 0.9562 - val_accuracy: 0.6615\n",
      "Epoch 43/100\n",
      "448/448 [==============================] - 81s 181ms/step - loss: 0.7423 - accuracy: 0.7220 - val_loss: 1.0239 - val_accuracy: 0.6495\n",
      "Epoch 44/100\n",
      "448/448 [==============================] - 81s 181ms/step - loss: 0.7282 - accuracy: 0.7259 - val_loss: 1.0277 - val_accuracy: 0.6551\n",
      "Epoch 45/100\n",
      "448/448 [==============================] - 81s 181ms/step - loss: 0.7123 - accuracy: 0.7362 - val_loss: 0.9876 - val_accuracy: 0.6609\n",
      "Epoch 46/100\n",
      "448/448 [==============================] - 81s 181ms/step - loss: 0.7002 - accuracy: 0.7383 - val_loss: 0.9790 - val_accuracy: 0.6693\n",
      "Epoch 47/100\n",
      "448/448 [==============================] - 81s 181ms/step - loss: 0.6925 - accuracy: 0.7430 - val_loss: 0.9643 - val_accuracy: 0.6715\n",
      "Epoch 48/100\n",
      "448/448 [==============================] - 81s 181ms/step - loss: 0.6775 - accuracy: 0.7464 - val_loss: 0.9988 - val_accuracy: 0.6551\n",
      "Epoch 49/100\n",
      "448/448 [==============================] - 81s 181ms/step - loss: 0.6719 - accuracy: 0.7477 - val_loss: 1.0021 - val_accuracy: 0.6615\n",
      "Epoch 50/100\n",
      "448/448 [==============================] - 81s 181ms/step - loss: 0.6591 - accuracy: 0.7528 - val_loss: 1.0391 - val_accuracy: 0.6539\n",
      "Epoch 51/100\n",
      "448/448 [==============================] - 81s 181ms/step - loss: 0.6493 - accuracy: 0.7574 - val_loss: 1.0613 - val_accuracy: 0.6542\n",
      "Epoch 52/100\n",
      "448/448 [==============================] - 81s 181ms/step - loss: 0.6427 - accuracy: 0.7620 - val_loss: 1.0483 - val_accuracy: 0.6567\n",
      "Epoch 53/100\n",
      "448/448 [==============================] - 81s 181ms/step - loss: 0.6299 - accuracy: 0.7633 - val_loss: 1.0356 - val_accuracy: 0.6715\n",
      "Epoch 54/100\n",
      "448/448 [==============================] - 81s 181ms/step - loss: 0.6234 - accuracy: 0.7672 - val_loss: 1.0163 - val_accuracy: 0.6729\n",
      "Epoch 55/100\n",
      "448/448 [==============================] - 81s 181ms/step - loss: 0.6139 - accuracy: 0.7707 - val_loss: 1.0330 - val_accuracy: 0.6740\n",
      "Epoch 56/100\n",
      "448/448 [==============================] - 81s 181ms/step - loss: 0.6044 - accuracy: 0.7782 - val_loss: 1.0046 - val_accuracy: 0.6824\n",
      "Epoch 57/100\n",
      "448/448 [==============================] - 81s 181ms/step - loss: 0.5955 - accuracy: 0.7771 - val_loss: 1.0038 - val_accuracy: 0.6682\n",
      "Epoch 58/100\n",
      "448/448 [==============================] - 68s 151ms/step - loss: 0.5967 - accuracy: 0.7825 - val_loss: 1.0128 - val_accuracy: 0.6726\n",
      "Epoch 59/100\n",
      "448/448 [==============================] - 55s 122ms/step - loss: 0.5772 - accuracy: 0.7838 - val_loss: 1.1345 - val_accuracy: 0.6606\n",
      "Epoch 60/100\n",
      "448/448 [==============================] - 58s 128ms/step - loss: 0.5699 - accuracy: 0.7882 - val_loss: 1.0653 - val_accuracy: 0.6726\n",
      "Epoch 61/100\n",
      "448/448 [==============================] - 54s 121ms/step - loss: 0.5571 - accuracy: 0.7919 - val_loss: 1.0794 - val_accuracy: 0.6645\n",
      "Epoch 62/100\n",
      "448/448 [==============================] - 53s 118ms/step - loss: 0.5494 - accuracy: 0.7939 - val_loss: 1.0661 - val_accuracy: 0.6779\n",
      "Epoch 63/100\n",
      "448/448 [==============================] - 58s 129ms/step - loss: 0.5450 - accuracy: 0.7994 - val_loss: 1.0459 - val_accuracy: 0.6701\n",
      "Epoch 64/100\n",
      "448/448 [==============================] - 53s 118ms/step - loss: 0.5339 - accuracy: 0.8024 - val_loss: 1.0661 - val_accuracy: 0.6668\n",
      "Epoch 65/100\n",
      "448/448 [==============================] - 55s 124ms/step - loss: 0.5234 - accuracy: 0.8052 - val_loss: 1.1060 - val_accuracy: 0.6701\n",
      "Epoch 66/100\n",
      "448/448 [==============================] - 54s 120ms/step - loss: 0.5186 - accuracy: 0.8063 - val_loss: 1.0820 - val_accuracy: 0.6776\n",
      "Epoch 67/100\n",
      "448/448 [==============================] - 54s 120ms/step - loss: 0.5109 - accuracy: 0.8100 - val_loss: 1.1044 - val_accuracy: 0.6821\n",
      "Epoch 68/100\n",
      "448/448 [==============================] - 56s 125ms/step - loss: 0.5033 - accuracy: 0.8139 - val_loss: 1.1577 - val_accuracy: 0.6584\n",
      "Epoch 69/100\n",
      "448/448 [==============================] - 57s 127ms/step - loss: 0.4909 - accuracy: 0.8169 - val_loss: 1.1371 - val_accuracy: 0.6732\n",
      "Epoch 70/100\n",
      "448/448 [==============================] - 59s 131ms/step - loss: 0.4863 - accuracy: 0.8197 - val_loss: 1.0894 - val_accuracy: 0.6757\n",
      "Epoch 71/100\n",
      "448/448 [==============================] - 57s 126ms/step - loss: 0.4775 - accuracy: 0.8224 - val_loss: 1.1469 - val_accuracy: 0.6704\n",
      "Epoch 72/100\n",
      "448/448 [==============================] - 54s 120ms/step - loss: 0.4702 - accuracy: 0.8265 - val_loss: 1.1260 - val_accuracy: 0.6799\n",
      "Epoch 73/100\n",
      "448/448 [==============================] - 53s 118ms/step - loss: 0.4602 - accuracy: 0.8303 - val_loss: 1.1727 - val_accuracy: 0.6779\n",
      "Epoch 74/100\n",
      "448/448 [==============================] - 56s 125ms/step - loss: 0.4610 - accuracy: 0.8295 - val_loss: 1.1528 - val_accuracy: 0.6765\n",
      "Epoch 75/100\n",
      "448/448 [==============================] - 54s 121ms/step - loss: 0.4475 - accuracy: 0.8352 - val_loss: 1.1923 - val_accuracy: 0.6651\n",
      "Epoch 76/100\n",
      "448/448 [==============================] - 53s 118ms/step - loss: 0.4458 - accuracy: 0.8348 - val_loss: 1.0998 - val_accuracy: 0.6721\n",
      "Epoch 77/100\n",
      "448/448 [==============================] - 53s 119ms/step - loss: 0.4283 - accuracy: 0.8402 - val_loss: 1.1853 - val_accuracy: 0.6799\n",
      "Epoch 78/100\n",
      "448/448 [==============================] - 54s 120ms/step - loss: 0.4240 - accuracy: 0.8435 - val_loss: 1.2745 - val_accuracy: 0.6721\n",
      "Epoch 79/100\n",
      "448/448 [==============================] - 54s 120ms/step - loss: 0.4193 - accuracy: 0.8414 - val_loss: 1.2358 - val_accuracy: 0.6648\n",
      "Epoch 80/100\n",
      "448/448 [==============================] - 56s 125ms/step - loss: 0.4131 - accuracy: 0.8477 - val_loss: 1.2001 - val_accuracy: 0.6771\n",
      "Epoch 81/100\n",
      "448/448 [==============================] - 53s 119ms/step - loss: 0.4076 - accuracy: 0.8504 - val_loss: 1.2126 - val_accuracy: 0.6812\n",
      "Epoch 82/100\n",
      "448/448 [==============================] - 54s 120ms/step - loss: 0.3978 - accuracy: 0.8519 - val_loss: 1.1711 - val_accuracy: 0.6843\n",
      "Epoch 83/100\n",
      "448/448 [==============================] - 53s 119ms/step - loss: 0.3999 - accuracy: 0.8516 - val_loss: 1.2683 - val_accuracy: 0.6743\n",
      "Epoch 84/100\n",
      "448/448 [==============================] - 53s 118ms/step - loss: 0.3857 - accuracy: 0.8557 - val_loss: 1.2292 - val_accuracy: 0.6709\n",
      "Epoch 85/100\n",
      "448/448 [==============================] - 50s 112ms/step - loss: 0.3798 - accuracy: 0.8613 - val_loss: 1.2595 - val_accuracy: 0.6712\n",
      "Epoch 86/100\n",
      "448/448 [==============================] - 52s 116ms/step - loss: 0.3809 - accuracy: 0.8602 - val_loss: 1.2535 - val_accuracy: 0.6801\n",
      "Epoch 87/100\n",
      "448/448 [==============================] - 53s 117ms/step - loss: 0.3757 - accuracy: 0.8609 - val_loss: 1.3175 - val_accuracy: 0.6721\n",
      "Epoch 88/100\n",
      "448/448 [==============================] - 49s 110ms/step - loss: 0.3667 - accuracy: 0.8656 - val_loss: 1.3536 - val_accuracy: 0.6679\n",
      "Epoch 89/100\n",
      "448/448 [==============================] - 54s 121ms/step - loss: 0.3600 - accuracy: 0.8671 - val_loss: 1.3632 - val_accuracy: 0.6631\n",
      "Epoch 90/100\n",
      "448/448 [==============================] - 60s 133ms/step - loss: 0.3518 - accuracy: 0.8677 - val_loss: 1.3024 - val_accuracy: 0.6779\n",
      "Epoch 91/100\n",
      "448/448 [==============================] - 52s 115ms/step - loss: 0.3546 - accuracy: 0.8708 - val_loss: 1.3169 - val_accuracy: 0.6743\n",
      "Epoch 92/100\n",
      "448/448 [==============================] - 54s 121ms/step - loss: 0.3424 - accuracy: 0.8755 - val_loss: 1.3243 - val_accuracy: 0.6771\n",
      "Epoch 93/100\n",
      "448/448 [==============================] - 53s 118ms/step - loss: 0.3456 - accuracy: 0.8702 - val_loss: 1.2900 - val_accuracy: 0.6776\n",
      "Epoch 94/100\n",
      "448/448 [==============================] - 53s 119ms/step - loss: 0.3310 - accuracy: 0.8778 - val_loss: 1.3415 - val_accuracy: 0.6826\n",
      "Epoch 95/100\n",
      "448/448 [==============================] - 53s 117ms/step - loss: 0.3295 - accuracy: 0.8763 - val_loss: 1.2755 - val_accuracy: 0.6799\n",
      "Epoch 96/100\n",
      "448/448 [==============================] - 52s 116ms/step - loss: 0.3308 - accuracy: 0.8801 - val_loss: 1.3167 - val_accuracy: 0.6829\n",
      "Epoch 97/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.3205 - accuracy: 0.8804 - val_loss: 1.3422 - val_accuracy: 0.6682\n",
      "Epoch 98/100\n",
      "448/448 [==============================] - 54s 119ms/step - loss: 0.3114 - accuracy: 0.8835 - val_loss: 1.3946 - val_accuracy: 0.6840\n",
      "Epoch 99/100\n",
      "448/448 [==============================] - 53s 117ms/step - loss: 0.3105 - accuracy: 0.8847 - val_loss: 1.3893 - val_accuracy: 0.6868\n",
      "Epoch 100/100\n",
      "448/448 [==============================] - 54s 119ms/step - loss: 0.3050 - accuracy: 0.8864 - val_loss: 1.4062 - val_accuracy: 0.6801\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "history = model.fit_generator(train_flow,\n",
    "                              steps_per_epoch=len(X_train) / batch_size,\n",
    "                              epochs=num_epochs,\n",
    "                              verbose=1,\n",
    "                              validation_data=test_flow,\n",
    "                              validation_steps = len(X_test)/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\asus\\.conda\\envs\\tf\\lib\\site-packages (4.9.0.80)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\asus\\.conda\\envs\\tf\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "model = model_from_json(open(\"model.json\", \"r\").read())\n",
    "model.load_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "face_haar_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    res, frame = cap.read()\n",
    "    print(res)  # Print the value of res\n",
    "\n",
    "    cv2.imshow('frame', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True\n",
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model, model_from_json\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "model = model_from_json(open(\"model.json\", \"r\").read())\n",
    "model.load_weights('model.h5')\n",
    "face_haar_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "if face_haar_cascade.empty():\n",
    "    print(\"Error loading cascade classifier XML file.\")\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    res, frame = cap.read()\n",
    "    print(res)  # Print the value of res\n",
    "\n",
    "    height, width, _ = frame.shape\n",
    "    sub_img = frame[0:int(height/6), 0:int(width)]\n",
    "\n",
    "    black_rect = np.ones(sub_img.shape, dtype=np.uint8) * 0\n",
    "    res = cv2.addWeighted(sub_img, 0.77, black_rect, 0.23, 0)\n",
    "    FONT = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    FONT_SCALE = 0.8\n",
    "    FONT_THICKNESS = 2\n",
    "    label_color = (10, 10, 255)\n",
    "    label = \"Detecting Emotions now...\"\n",
    "    label_dimension = cv2.getTextSize(label, FONT, FONT_SCALE, FONT_THICKNESS)[0]\n",
    "    textX = int((res.shape[1] - label_dimension[0]) / 2)\n",
    "    textY = int((res.shape[0] + label_dimension[1]) / 2)\n",
    "    cv2.putText(res, label, (textX, textY), FONT, FONT_SCALE, (0, 0, 0), FONT_THICKNESS)\n",
    "\n",
    "    gray_image = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_haar_cascade.detectMultiScale(gray_image)\n",
    "    if frame is None:\n",
    "        print(\"Frame is None. Check your camera connection or configuration.\")\n",
    "        break  # Break out of the loop if frame is None\n",
    "\n",
    "    try:\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, pt1=(x, y), pt2=(x + w, y + h), color=(255, 0, 0), thickness=2) #rect blue\n",
    "            roi_gray = gray_image[y-5:y+h+5, x-5:x+w+5] #region of interest\n",
    "            roi_gray = cv2.resize(roi_gray, (48, 48)) #resize\n",
    "            image_pixels = img_to_array(roi_gray) #arrayfication\n",
    "            image_pixels = np.expand_dims(image_pixels, axis=0) #dim padding\n",
    "            image_pixels /= 255 #norm\n",
    "            predictions = model.predict(image_pixels)\n",
    "            max_index = np.argmax(predictions)\n",
    "            # print(predictions[1]) out of bounds\n",
    "            emotion_detection = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
    "            emotion_prediction = emotion_detection[max_index]\n",
    "            cv2.putText(res, \"Sentiment: {}\".format(emotion_prediction), (0, textY + 22 + 5), FONT, 0.7, label_color, 2)\n",
    "            label_violation = 'Confidence: {}'.format(str(np.round(np.max(predictions[0]) * 100, 1)) + \"%\")\n",
    "            violation_text_dimension = cv2.getTextSize(label_violation, FONT, FONT_SCALE, FONT_THICKNESS)[0]\n",
    "            violation_x_axis = int(res.shape[1] - violation_text_dimension[0])\n",
    "            cv2.putText(res, label_violation, (violation_x_axis, textY + 22 + 5), FONT, 0.7, label_color, 2)\n",
    "    except Exception as e:\n",
    "        print(\"An exception occurred:\", e)\n",
    "\n",
    "    frame[0:int(height/6), 0:int(width)] = res\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF   \n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 449ms/step\n",
      "Neutral time:  17:58:08\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Neutral time:  17:58:08\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Neutral time:  17:58:08\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Neutral time:  17:58:08\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Neutral time:  17:58:08\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Neutral time:  17:58:08\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Neutral time:  17:58:09\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Neutral time:  17:58:09\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Neutral time:  17:58:09\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Neutral time:  17:58:09\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Neutral time:  17:58:09\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Neutral time:  17:58:09\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Neutral time:  17:58:09\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Neutral time:  17:58:10\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Neutral time:  17:58:10\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Neutral time:  17:58:10\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Neutral time:  17:58:10\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Neutral time:  17:58:10\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Neutral time:  17:58:10\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Neutral time:  17:58:10\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Neutral time:  17:58:11\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Neutral time:  17:58:11\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Neutral time:  17:58:11\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Neutral time:  17:58:11\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Neutral time:  17:58:11\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Neutral time:  17:58:11\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Neutral time:  17:58:11\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Neutral time:  17:58:12\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Neutral time:  17:58:12\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Neutral time:  17:58:12\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Neutral time:  17:58:12\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Neutral time:  17:58:12\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Neutral time:  17:58:13\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Neutral time:  17:58:13\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model, model_from_json\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "# Load the model\n",
    "model = model_from_json(open(\"model.json\", \"r\").read())\n",
    "model.load_weights('model.h5')\n",
    "\n",
    "# Load the face cascade classifier\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "if face_cascade.empty():\n",
    "    print(\"Error loading cascade classifier XML file.\")\n",
    "\n",
    "# Start capturing video from the camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    res, frame = cap.read()\n",
    "    if not res:\n",
    "        print(\"Failed to capture frame\")\n",
    "        break\n",
    "\n",
    "    # Convert the frame to grayscale\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the frame\n",
    "    faces = face_cascade.detectMultiScale(gray_frame, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    # Iterate over each detected face\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Extract the face ROI (Region of Interest)\n",
    "        face_roi = gray_frame[y:y+h, x:x+w]\n",
    "        \n",
    "        # Resize the face ROI to match the input shape of the model\n",
    "        resized_face = cv2.resize(face_roi, (48, 48))\n",
    "        \n",
    "        # Convert the resized face to an array\n",
    "        image_pixels = img_to_array(resized_face)\n",
    "        \n",
    "        # Expand dimensions to match the model input shape\n",
    "        image_pixels = np.expand_dims(image_pixels, axis=0)\n",
    "        \n",
    "        # Normalize the image\n",
    "        image_pixels /= 255.0\n",
    "        \n",
    "        # Perform prediction\n",
    "        predictions = model.predict(image_pixels)\n",
    "        \n",
    "        # Get the predicted class\n",
    "        predicted_class = np.argmax(predictions[0])\n",
    "        \n",
    "        # Map predicted class to emotion label\n",
    "        emotion_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "        emotion_label = emotion_labels[predicted_class]\n",
    "        print(emotion_label,\"| time: \", time.strftime(\"%H:%M:%S\", time.localtime()))\n",
    "        \n",
    "        # Display the emotion label on the frame\n",
    "        cv2.putText(frame, emotion_label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "        \n",
    "        # Draw a rectangle around the face\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('frame', frame)\n",
    "    \n",
    "    # Check if the user pressed 'q' to quit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the capture and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcap\u001b[49m\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m      2\u001b[0m cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cap' is not defined"
     ]
    }
   ],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.11 (tf)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
